# local_llm_ollama_langchain
The popularity of projects like PrivateGPT, llama.cpp, Ollama, GPT4All, llamafile, and others underscore the demand to run LLMs locally (on your own device).

# Links
- [Run LLMs locally](https://python.langchain.com/docs/guides/development/local_llms/)
- [Install Ollama](https://ollama.com/download)
- 

# Instructions
1. Install Ollama
1. Pull llama3 
    1. # ollama pull llama3
1. 